# Copyright 2013-present Barefoot Networks, Inc.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Thrift PD interface basic tests
"""

from collections import OrderedDict

import time
import sys
import logging
import copy
import pdb
import unittest
import random

from ptf import config

import pd_base_tests
from ptf.testutils import *
from ptf.thriftutils import *
from ptf_port import *

from bfruntime_client_base_tests import BfRuntimeTest
import bfrt_grpc.bfruntime_pb2 as bfruntime_pb2
import bfrt_grpc.client as gc

# PD-Fixed
from res_pd_rpc.ttypes import *
from pal_rpc.ttypes import *
from conn_mgr_pd_rpc.ttypes import *
from mc_pd_rpc.ttypes import *
from devport_mgr_pd_rpc.ttypes import *
from pkt_pd_rpc.ttypes import *
from tm_api_rpc.ttypes import *
from mirror_pd_rpc.ttypes import *

# P4-PD
from t2na_pgr.p4_pd_rpc.ttypes import *

logger = logging.getLogger('Test')
logger.addHandler(logging.StreamHandler())

dev_id = 0
client_id = 0
p4_name = "t2na_pgr"

swports = []
pgen_ports = []
recirc_ports = []
num_pipes = int(test_param_get('num_pipes'))
for device, port, ifname in config["interfaces"]:
    pipe = port >> 7
    if pipe in range(num_pipes):
        swports.append(port)
swports.sort()

g_target_model = test_param_get('target').lower() == "asic-model"
g_target_hw = test_param_get('target').lower() == "hw"
g_tofino2 = test_param_get("arch") == "tofino2"

if g_tofino2:
  for pipe in range(num_pipes):
    for local_port in range(0,8):
      pgen_ports.append((pipe << 7) | local_port)
      recirc_ports.append((pipe << 7) | local_port)

fpports = list(swports)
for p in pgen_ports + recirc_ports:
  if p in fpports:
    fpports.remove(p)

all_app_ids = range(16)
def setup_random(seed_val=None):
    if seed_val is None:
        seed_val = int(time.time())
    logger.info("Seed is: %d", seed_val)
    random.seed(seed_val)

def make_port(pipe, local_port):
    assert pipe >= 0 and pipe < 4
    assert local_port >= 0 and local_port < 72
    return pipe << 7 | local_port
def port_to_pipe(port):
    return port >> 7
def port_to_local_port(port):
    return port & 0x7F

def rmv_special_ports(test):
  # Remove all packet-gen and recirc ports.  The Ethernet CPU port is deleted
  # through PAL while the internal ports are deleted through DVM.
  eth_cpu = test.devport_mgr.devport_mgr_eth_cpu_port_get(dev_id)
  for i in range(4):
    try:
      test.pal.pal_port_del(dev_id, eth_cpu + i)
      #logger.info("Removed eth-cpu %d", eth_cpu + i)
    except InvalidPalOperation:
      pass
  for p in pgen_ports + recirc_ports:
    try:
      #logger.info("Trying to remove recirc port %d", p)
      test.devport_mgr.devport_mgr_remove_port(dev_id, p)
      #logger.info(Remove recirc port %d", p)
    except InvalidDevportMgrOperation:
      #logger.info(Recirc port %d already gone", p)
      pass

def ports_down(test, ports):
  if g_target_hw:
    for port in ports:
      test.pal.pal_port_dis(dev_id, port)
  else:
    for port in ports:
      take_port_down(port)
    time.sleep(3)

def ports_up(test, ports):
  if g_target_hw:
    for port in ports:
      test.pal.pal_port_enable(dev_id, port)
    time.sleep(5)
  else:
    for port in ports:
      bring_port_up(port)
    time.sleep(3)

def wait_for_generation(test, shdl, dt, app_id, tmo=0.5):
  """
  Wait for the packet counter to stop increasing.
  """
  pkt_cnt = test.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
  while True:
    cnt = test.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
    if cnt == pkt_cnt:
      # Count has not increased; wait and check again.
      time.sleep(tmo)
      cnt = test.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      if cnt == pkt_cnt:
        # Count has still not increased so assume it is done.
        break
    pkt_cnt = cnt

def populate_port_down_batch_check(test, ports, trgt=None):
  if not trgt:
    trgt = gc.Target(device_id=dev_id, pipe_id=0xFFFF)
  t = test.bfrt_info.table_get('i.t_port_down_batch_check')
  for port in ports:
    t.entry_add(trgt,
                [t.make_key([gc.KeyTuple('md.batch_id', port)])],
                [t.make_data([], 'i.batch_id_okay')])


def add_p0_entry(test, trgt, port, sw_read_back=False, hw_read_back=False, do_dprsr_trigger=False, is_valid=True, is_pktgen=False, dst_port=None, dprsr_trigger_offset=0, dprsr_trigger_len=0, dprsr_trigger_hdr_idx=0, pad=0, verify_tbl_only=False):
  if dst_port is None: dst_port = port
  t_p0 = test.bfrt_info.table_get('iPrsr.$PORT_METADATA')
  p0_key = [t_p0.make_key([gc.KeyTuple('ig_intr_md.ingress_port', port)])]
  p0_data = [t_p0.make_data([gc.DataTuple('do_dprsr_trigger',      int(do_dprsr_trigger)),
                             gc.DataTuple('is_valid',              int(is_valid)),
                             gc.DataTuple('is_pktgen',             int(is_pktgen)),
                             gc.DataTuple('dst_port',              dst_port),
                             gc.DataTuple('dprsr_trigger_hdr_idx', dprsr_trigger_hdr_idx),
                             gc.DataTuple('dprsr_trigger_offset',  dprsr_trigger_offset),
                             gc.DataTuple('dprsr_trigger_len',     dprsr_trigger_len),
                             gc.DataTuple('pad',                   pad)])]
  if verify_tbl_only is False:
    t_p0.entry_add(trgt, p0_key, p0_data)

  t_v  = test.bfrt_info.table_get('i.port_metadata')
  v_key = [t_v.make_key([gc.KeyTuple('ig_intr_md.ingress_port',          port),
                         gc.KeyTuple('md.port_md.do_dprsr_trigger',      int(do_dprsr_trigger)),
                         gc.KeyTuple('md.port_md.is_valid',              int(is_valid)),
                         gc.KeyTuple('md.port_md.is_pktgen',             int(is_pktgen)),
                         gc.KeyTuple('md.port_md.dst_port',              dst_port),
                         gc.KeyTuple('md.port_md.dprsr_trigger_hdr_idx', dprsr_trigger_hdr_idx),
                         gc.KeyTuple('md.port_md.dprsr_trigger_offset',  dprsr_trigger_offset),
                         gc.KeyTuple('md.port_md.dprsr_trigger_len',     dprsr_trigger_len),
                         gc.KeyTuple('md.port_md.pad',                   pad)])]
  v_data = [t_v.make_data([], 'i.match')]

  # The entry may or may not be in the table already; get all entries and
  # check if there is an entry for this port and delete it.
  for data,key in t_v.entry_get(trgt, None, {"from_hw":False}):
    key_dict = key.to_dict()
    if key_dict['ig_intr_md.ingress_port']['value'] == port:
      t_v.entry_del(trgt, [key])
  t_v.entry_add(trgt, v_key, v_data)

  if not sw_read_back and not hw_read_back: return

  modes = []
  if sw_read_back:
    modes.append(False)
  if hw_read_back:
    modes.append(True)
  for mode in modes:
    resp = t_p0.entry_get(trgt, p0_key, {"from_hw":mode})
    fields = next(resp)[0].to_dict()
    test.assertEqual(fields['do_dprsr_trigger'],      int(do_dprsr_trigger))
    test.assertEqual(fields['is_valid'],              int(is_valid))
    test.assertEqual(fields['is_pktgen'],             int(is_pktgen))
    test.assertEqual(fields['dst_port'],              dst_port)
    test.assertEqual(fields['dprsr_trigger_hdr_idx'], dprsr_trigger_hdr_idx)
    test.assertEqual(fields['dprsr_trigger_offset'],  dprsr_trigger_offset)
    test.assertEqual(fields['dprsr_trigger_len'],     dprsr_trigger_len)
    test.assertEqual(fields['pad'],                   pad)

    resp = t_v.entry_get(trgt, v_key, {"from_hw":mode})
    fields = next(resp)[0].to_dict()
    test.assertEqual(fields['action_name'], 'i.match')


def del_p0_entry(test, trgt, port):
  t_p0 = test.bfrt_info.table_get('iPrsr.$PORT_METADATA')
  p0_key = [t_p0.make_key([gc.KeyTuple('ig_intr_md.ingress_port', port)])]
  t_p0.entry_del(trgt, p0_key)

  t_v  = test.bfrt_info.table_get('i.port_metadata')
  v_key = [t_v.make_key([gc.KeyTuple('ig_intr_md.ingress_port',          port),
                         gc.KeyTuple('md.port_md.do_dprsr_trigger',      0),
                         gc.KeyTuple('md.port_md.is_valid',              0),
                         gc.KeyTuple('md.port_md.is_pktgen',             0),
                         gc.KeyTuple('md.port_md.dst_port',              0),
                         gc.KeyTuple('md.port_md.dprsr_trigger_hdr_idx', 0),
                         gc.KeyTuple('md.port_md.dprsr_trigger_offset',  0),
                         gc.KeyTuple('md.port_md.dprsr_trigger_len',     0),
                         gc.KeyTuple('md.port_md.pad',                   0)])]
  v_data = [t_v.make_data([], 'i.match')]

  # We are potentially changing the key of an entry in the table.  The key is
  # the port number and all the expected phase0 data and the expected data is
  # being updated.  First do a get to see if there are any entries in the table
  # which have our port number as the key, if there are, delete them.  Then we
  # can add a new entry with the new expected data.
  for data,key in t_v.entry_get(trgt, None, {"from_hw":False}):
    key_dict = key.to_dict()
    if key_dict['ig_intr_md.ingress_port']['value'] == port:
      t_v.entry_del(trgt, [key])
  t_v.entry_add(trgt, v_key, v_data)


def cleanup_one_table(test, tbl, trgt=None):
  if not trgt:
    trgt = gc.Target(device_id=dev_id, pipe_id=0xFFFF)
  #logger.info("Cleanup: Getting entries from " + tbl)
  t = test.bfrt_info.table_get(tbl)
  for data,key in t.entry_get(trgt, None, {"from_hw":False}):
    t.entry_del(trgt, [key])

def cleanup_cntr_table(test, tbl, trgt=None):
  if not trgt:
    trgt = gc.Target(device_id=dev_id, pipe_id=0xFFFF)
  #logger.info("Cleanup counter " + tbl)
  t = test.bfrt_info.table_get(tbl)
  fields = t.info.data_field_name_list_get()
  data_tuples = [gc.DataTuple(n,0) for n in ['$COUNTER_SPEC_PKTS','$COUNTER_SPEC_BYTES'] if n in fields]
  for i in range(t.info.size_get()):
    t.entry_add(trgt,
                [t.make_key([gc.KeyTuple('$COUNTER_INDEX', i)])],
                [t.make_data(data_tuples)])

def cleanup_fifos(test):
  shdl = test.conn_mgr.client_init()
  prop = tbl_property_t.TBL_PROP_TBL_ENTRY_SCOPE
  prop_val = tbl_property_value_t.ENTRY_SCOPE_SINGLE_PIPELINE
  test.client.i_log_ts_1_set_property(shdl, dev_id, prop, prop_val, 0)
  test.client.i_log_ts_2_set_property(shdl, dev_id, prop, prop_val, 0)
  for p in range(num_pipes):
    test.client.register_reset_i_ts_fifo_1(shdl, DevTarget_t(dev_id, p))
    test.client.register_reset_i_ts_fifo_2(shdl, DevTarget_t(dev_id, p))
  test.conn_mgr.client_cleanup(shdl)

def cleanup(test):
  cleanup_fifos(test)

  trgt = gc.Target(device_id=dev_id, pipe_id=0xFFFF)
  dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))

  # Remove all match entries.
  for t in ['i.app_info', 'i.t_port_down_batch_check', 'i.t_app_ctx_check', 'i.port_metadata', 'i.t_set_dprsr_trig_hdr', 'iPrsr.$PORT_METADATA']:
    cleanup_one_table(test, t, trgt)

  # Remove all PVS entries.
  for t in ['iPrsr.timer_apps', 'iPrsr.port_down_apps', 'iPrsr.recirc_dprsr_apps', 'iPrsr.pfc_apps']:
    cleanup_one_table(test, t, trgt)

  # Reset all counter tables to zero.
  for c in ['i.ctx_cntr', 'i.seq_no_cntr', 'i.port_cntr', 'i.port_down_cntr', 'i.port_metadata_cntr']:
    cleanup_cntr_table(test, c, trgt)

  # Clean up register tables.
  shdl = test.conn_mgr.client_init()
  test.client.register_reset_all_i_pkt_seq_num(shdl, dt)
  test.client.register_reset_all_i_batch_seq_num(shdl, dt)
  test.conn_mgr.client_cleanup(shdl)

  # Disable all packet gen apps.
  shdl = test.conn_mgr.client_init()
  for app_id in range(16):
    test.conn_mgr.pktgen_app_disable(shdl, dt, app_id)

  # Reset the app counters.
  for app_id in range(16):
    test.conn_mgr.pktgen_set_trigger_counter(shdl, dt, app_id, 0)
    test.conn_mgr.pktgen_set_batch_counter(shdl, dt, app_id, 0)
    test.conn_mgr.pktgen_set_pkt_counter(shdl, dt, app_id, 0)

  # Clear port-down state in the packet generator
  for port in swports:
    test.conn_mgr.pktgen_clear_port_down(shdl, dev_id, port)

  # Reset the port-mask
  for which in [0,1]:
    test.conn_mgr.pktgen_cfg_port_mask_tof2(shdl, dt, which, PortMask_t(mask = [hex_to_byte(255)]*9))

  # Disable packet generation.
  for p in pgen_ports:
    try:
      test.conn_mgr.pktgen_disable(shdl, dev_id, p)
    except InvalidPktGenOperation:
      pass

  eth_cpu = test.devport_mgr.devport_mgr_eth_cpu_port_get(dev_id)
  pcie_cpu = test.devport_mgr.devport_mgr_pcie_cpu_port_get(dev_id)

  # Remove all packet-gen and recirc ports.
  rmv_special_ports(test)

  # Restore the recirculation setting to default; enabled for all ports except
  # the two CPU ports.
  for p in recirc_ports:
    test.conn_mgr.recirculation_enable(shdl, dev_id, p)
  test.conn_mgr.recirculation_disable(shdl, dev_id, pcie_cpu)
  # Disable recirculation on all four channels of the CPU port
  test.conn_mgr.recirculation_disable(shdl, dev_id, eth_cpu)
  test.conn_mgr.recirculation_disable(shdl, dev_id, eth_cpu+1)
  test.conn_mgr.recirculation_disable(shdl, dev_id, eth_cpu+2)
  test.conn_mgr.recirculation_disable(shdl, dev_id, eth_cpu+3)

  # Add the CPU ports back.
  test.pal.pal_port_add(dev_id, eth_cpu, pal_port_speed_t.BF_SPEED_10G, pal_fec_type_t.BF_FEC_TYP_NONE)
  test.devport_mgr.devport_mgr_add_port(dev_id, pcie_cpu, bf_port_speeds.BF_PORT_SPEED_25G, bf_fec_types.BF_FEC_TYP_NONE)

  test.conn_mgr.complete_operations(shdl)
  test.conn_mgr.client_cleanup(shdl)

def get_cntr(test, trgt, tbl, idx):
  t = test.bfrt_info.table_get(tbl)
  resp = t.entry_get(trgt,
                     [t.make_key([gc.KeyTuple('$COUNTER_INDEX', idx)])],
                     {"from_hw":True},
                     None)

  data_dict = next(resp)[0].to_dict()
  if '$COUNTER_SPEC_PKTS' in data_dict:
    recv_pkts = data_dict['$COUNTER_SPEC_PKTS']
  else:
    recv_pkts = 0
  if '$COUNTER_SPEC_BYTES' in data_dict:
    recv_bytes = data_dict['$COUNTER_SPEC_BYTES']
  else:
    recv_bytes = 0
  p_name = 'pkt '
  if recv_pkts > 1: p_name = 'pkts'
  logger.info("%s[%d] = %d %s %d bytes", tbl, idx, recv_pkts, p_name, recv_bytes)
  return recv_pkts,recv_bytes

def clr_cntr(test, trgt, tbl, idx):
  t = test.bfrt_info.table_get(tbl)
  fields = t.info.data_field_name_list_get()
  data_tuples = [gc.DataTuple(n,0) for n in ['$COUNTER_SPEC_PKTS','$COUNTER_SPEC_BYTES'] if n in fields]
  t.entry_add(trgt,
              [t.make_key([gc.KeyTuple('$COUNTER_INDEX', idx)])],
              [t.make_data(data_tuples)])

class TestPortMetadata(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    app_id = random.choice(all_app_ids)
    pgen_port = 6
    pgen_port_speed = bf_port_speeds.BF_PORT_SPEED_100G
    self.warm_init = False
    try:
      rmv_special_ports(self)
      shdl = self.conn_mgr.client_init()

      # Create data for each port.
      keys = set()
      for pipe in range(num_pipes):
        for local_port in range(72):
          port = make_port(pipe, local_port)
          keys.add(port)
          # Construct the phase0 data.  Set the valid bit to zero, and the
          # dprsr_trigger bit to zero; everything else is random data.
          add_p0_entry(self, trgt, port,
                       sw_read_back=True,
                       hw_read_back=True,
                       is_valid=False,
                       do_dprsr_trigger=False,
                       is_pktgen=random.choice([True,False]),
                       dst_port=random.randint(0, 0x1FF),
                       dprsr_trigger_offset=random.randint(0, 0x3FFF),
                       dprsr_trigger_len=random.randint(0, 0x3FF),
                       dprsr_trigger_hdr_idx=random.randint(0, 0xF),
                       pad=random.randint(0, 0xFFffffFFFF))

      # Clear counter table.
      cleanup_cntr_table(self, 'i.port_metadata_cntr', trgt)
      cleanup_cntr_table(self, 'i.port_cntr', trgt)

      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)

      # Use a timer app to generate a packet for every port.
      # The ports do not need to be up or even created since the phase0 data
      # comes from an SRAM in the PGR block, not from IPB registers.
      pkt_size = 60
      exp_pkt_size = pkt_size + 6 + 4 # Includes 6 bytes of PGen header and 4 bytes CRC
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                                ipg=0,
                                pkt_count=71,
                                buffer_offset=0,
                                length=pkt_size,
                                assigned_chnl_id=pgen_port,
                                src_port=0,
                                src_port_inc=1,
                                source_port_wrap_max=71)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      p = simple_ip_packet()
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, 54, str(p))
      self.conn_mgr.pktgen_set_pkt_counter(shdl, dt, app_id, 0)
      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
      self.conn_mgr.complete_operations(shdl)
      wait_for_generation(self, shdl, dt, app_id)
      time.sleep(5)
      cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      self.assertEqual(cnt, num_pipes * 72)

      # Verify counter table.
      failed = False
      for port in keys:
        p,b = get_cntr(self, trgt, 'i.port_metadata_cntr', port)
        if p != 1:
          logger.error("Port %d expected port-meta cntr to be 1 but it is %d", port, p)
          failed = True
      self.assertFalse(failed)
      for port in keys:
        p,b = get_cntr(self, trgt, 'i.port_cntr', port)
        if p != 1:
          logger.error("Port %d expected port cntr to be 1 but it is %d", port, p)
          failed = True
        if b != p*exp_pkt_size:
          logger.error("Port %d expected port byte cntr to be %d but it is %d", port, p*exp_pkt_size, b)
          failed = True
      self.assertFalse(failed)

      # Clear counter table.
      cleanup_cntr_table(self, 'i.port_metadata_cntr', trgt)
      cleanup_cntr_table(self, 'i.port_cntr', trgt)

      # Clear the entries and make sure the phase0 data goes back to zero.
      for key in keys:
        del_p0_entry(self, trgt, key)
      self.conn_mgr.pktgen_app_disable(shdl, dt, app_id)
      self.conn_mgr.pktgen_set_pkt_counter(shdl, dt, app_id, 0)
      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
      self.conn_mgr.complete_operations(shdl)
      wait_for_generation(self, shdl, dt, app_id)
      time.sleep(5)
      cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      self.assertEqual(cnt, num_pipes * 72)

      # Verify counter table.
      failed = False
      for port in keys:
        p,b = get_cntr(self, trgt, 'i.port_metadata_cntr', port)
        if p != 1:
          logger.error("Port %d expected P0 cntr to be 1 but it is %d", port, p)
          failed = True
      self.assertFalse(failed)

      # Fast reconfig without replaying phase0 entries.
      BfRuntimeTest.tearDown(self)
      logger.info("Calling warm init begin done")
      self.devport_mgr.devport_mgr_warm_init_begin(dev_id, dev_init_mode.DEV_WARM_INIT_FAST_RECFG, dev_serdes_upgrade_mode.DEV_SERDES_UPD_NONE, True)
      self.warm_init = True
      logger.info("Warm init begin done")
      BfRuntimeTest.setUp(self, client_id, p4_name)

      rmv_special_ports(self)

      # Setup the packet generator again...
      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                                ipg=0,
                                pkt_count=71,
                                buffer_offset=0,
                                length=58,
                                assigned_chnl_id=pgen_port,
                                src_port=0,
                                src_port_inc=1,
                                source_port_wrap_max=71)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      p = simple_ip_packet()
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, 54, str(p))
      self.conn_mgr.pktgen_set_pkt_counter(shdl, dt, app_id, 0)

      # Populate the verify table for phase0 data that is all zeros
      for pipe in range(num_pipes):
        for local_port in range(72):
          port = make_port(pipe, local_port)
          add_p0_entry(self, trgt, port,
                       sw_read_back=False,
                       hw_read_back=False,
                       is_valid=False,
                       do_dprsr_trigger=False,
                       is_pktgen=False,
                       dst_port=0,
                       dprsr_trigger_offset=0,
                       dprsr_trigger_len=0,
                       dprsr_trigger_hdr_idx=0,
                       pad=0,
                       verify_tbl_only=True)

      logger.info("Calling warm init end")
      self.devport_mgr.devport_mgr_warm_init_end(dev_id);
      self.warm_init = False
      logger.info("Warm init end done")

      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
      self.conn_mgr.complete_operations(shdl)
      wait_for_generation(self, shdl, dt, app_id)
      time.sleep(5)
      cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      self.assertEqual(cnt, num_pipes * 72)

      # Verify counter table.
      failed = False
      for port in keys:
        p,b = get_cntr(self, trgt, 'i.port_metadata_cntr', port)
        if p != 1:
          logger.error("Port %d expected P0 cntr to be 1 but it is %d", port, p)
          failed = True
      self.assertFalse(failed)


      # Fast reconfig with phase0 data.
      BfRuntimeTest.tearDown(self)
      logger.info("Calling warm init begin done")
      self.devport_mgr.devport_mgr_warm_init_begin(dev_id, dev_init_mode.DEV_WARM_INIT_FAST_RECFG, dev_serdes_upgrade_mode.DEV_SERDES_UPD_NONE, True)
      self.warm_init = True
      logger.info("Warm init begin done")
      BfRuntimeTest.setUp(self, client_id, p4_name)

      rmv_special_ports(self)

      # Setup the packet generator again...
      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)

      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                                ipg=0,
                                pkt_count=71,
                                buffer_offset=0,
                                length=58,
                                assigned_chnl_id=pgen_port,
                                src_port=0,
                                src_port_inc=1,
                                source_port_wrap_max=71)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      p = simple_ip_packet()
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, 54, str(p))

      for pipe in range(num_pipes):
        for local_port in range(72):
          port = make_port(pipe, local_port)
          keys.add(port)
          # Construct the phase0 data.  Set the valid bit to zero, and the
          # dprsr_trigger bit to zero; everything else is random data.
          add_p0_entry(self, trgt, port,
                       sw_read_back=True,
                       hw_read_back=False, # Don't read HW during warm init
                       is_valid=False,
                       do_dprsr_trigger=False,
                       is_pktgen=random.choice([True,False]),
                       dst_port=random.randint(0, 0x1FF),
                       dprsr_trigger_offset=random.randint(0, 0x3FFF),
                       dprsr_trigger_len=random.randint(0, 0x3FF),
                       dprsr_trigger_hdr_idx=random.randint(0, 0xF),
                       pad=random.randint(0, 0xFFffffFFFF))

      logger.info("Calling warm init end")
      self.devport_mgr.devport_mgr_warm_init_end(dev_id);
      self.warm_init = True
      logger.info("Warm init end done")

      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
      self.conn_mgr.complete_operations(shdl)
      wait_for_generation(self, shdl, dt, app_id)
      time.sleep(5)
      cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      self.assertEqual(cnt, num_pipes * 72)

      # Verify counter table.
      failed = False
      for port in keys:
        p,b = get_cntr(self, trgt, 'i.port_metadata_cntr', port)
        if p != 1:
          logger.error("Port %d expected P0 cntr to be 1 but it is %d", port, p)
          failed = True
      self.assertFalse(failed)

      logger.info("Success")
    finally:
      logger.info("Starting cleanup")
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)




class TestPortDown(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    pktlen = 64
    pgen_port = 7 # Use port 7 in each pipe for pktgen
    pgen_port_speed = bf_port_speeds.BF_PORT_SPEED_50G
    ingr_port = 7 # Fake ingress port
    if g_target_model:
      batch_size = 1 + random.choice(range(7))
    else:
      batch_size = 1 + random.choice(range(16*1024))
    app_id = random.choice(all_app_ids)
    logger.info("App %d: %d packets", app_id, batch_size)
    try:
      cleanup(self)
      shdl = self.conn_mgr.client_init()
      rmv_special_ports(self)

      # Set up the app-info table
      t = self.bfrt_info.table_get('i.app_info')
      t.entry_add(trgt,
                  [t.make_key([gc.KeyTuple('md.app_id', app_id)])],
                  [t.make_data([gc.DataTuple('type', 2),
                                gc.DataTuple('batch_count', 0),
                                gc.DataTuple('batch_size', batch_size-1)],
                               'i.init_app_info')])
      # Set up the parser.
      t = self.bfrt_info.table_get('iPrsr.port_down_apps')
      t.entry_add(trgt, [t.make_key([gc.KeyTuple('app_id', app_id, 0xF)])], None)

      # Set up the phase0 data.
      for pipe in range(num_pipes):
        port = make_port(pipe, ingr_port)
        add_p0_entry(self, trgt, port, is_pktgen=True, dst_port=swports[-1])

      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)

      # Configure a port-down app.
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.PORT_DOWN,
                                ipg=0,
                                pkt_count=batch_size-1,
                                buffer_offset=0,
                                length=pktlen,
                                port_mask_sel=0,
                                assigned_chnl_id=pgen_port,
                                src_port=ingr_port)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      p = simple_ip_packet(pktlen=pktlen)
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, pktlen, str(p))

      # Set the port down replay mode to none (should be the default).
      self.conn_mgr.pktgen_port_down_replay_mode_set(shdl, dt, PktGenPortDownReplay_t.REPLAY_NONE)
      self.conn_mgr.complete_operations(shdl)
      queried_pgen_mode = self.conn_mgr.pktgen_port_down_replay_mode_get(shdl, dt)
      self.assertEqual(queried_pgen_mode, PktGenPortDownReplay_t.REPLAY_NONE)

      # Put the front pannel ports in the port down mask
      for pipe in range(num_pipes):
        m = [0]*9
        for full_port in fpports:
          if pipe != port_to_pipe(full_port): continue
          port = port_to_local_port(full_port)
          m[port / 8] |= 1 << (port % 8)
          for i in range(len(m)):
            m[i] = hex_to_byte(m[i])
        self.conn_mgr.pktgen_cfg_port_mask_tof2(shdl, DevTarget_t(dev_id, pipe), 0, PortMask_t(mask = m))

      # Clear the port down state for our ports
      self.conn_mgr.begin_batch(shdl)
      for port in fpports:
        self.conn_mgr.pktgen_clear_port_down(shdl, dev_id, port)
      self.conn_mgr.end_batch(shdl, True)

      # Enable the app.
      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)

      self.conn_mgr.complete_operations(shdl)
      for port in fpports:
        logger.info("Checking port %d", port)
        # Add an entry to validate the port number
        populate_port_down_batch_check(self, [port])
        # Bring the port down.
        ports_down(self, [port])
        # Wait for packets to be generated.
        wait_for_generation(self, shdl, dt, app_id)
        # Verify that pkt-gen triggered.
        # Verify the app counts for batchs and packets.
        # Verify the seq-num table counts.
        self.verify_trigger(shdl, trgt, app_id, batch_size, [port])
        # Bring port down again, it should not trigger.
        ports_up(self, [port])
        ports_down(self, [port])
        self.verify_trigger(shdl, trgt, app_id, batch_size, [])
        ports_up(self, [port])

        # Clear port down state.
        self.conn_mgr.pktgen_clear_port_down(shdl, dev_id, port)

        # Clean up the table entries
        cleanup_one_table(self, 'i.t_port_down_batch_check')
      logger.info("Checked all ports")

      for mode,pgen_mode in [('all', PktGenPortDownReplay_t.REPLAY_ALL), \
                             ('missed', PktGenPortDownReplay_t.REPLAY_MISSED)]:
        logger.info("Checking replay-%s mode", mode)
        # Disable app, change the replay mode.
        self.conn_mgr.pktgen_app_disable(shdl, dt, app_id)
        self.conn_mgr.pktgen_port_down_replay_mode_set(shdl, dt, pgen_mode)
        self.conn_mgr.complete_operations(shdl)
        queried_pgen_mode = self.conn_mgr.pktgen_port_down_replay_mode_get(shdl, dt)
        self.assertEqual(queried_pgen_mode, pgen_mode)
        # Set up the table entries to validate
        populate_port_down_batch_check(self, fpports)
        # Enable app
        logger.info("Enabling port down app %d", app_id)
        self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
        self.conn_mgr.complete_operations(shdl)
        # Divide the set of ports in half.  Disable half while the app is enabled
        # and verify, then disable the app and bring down the other half.  On
        # enabling the app events should be generated for all ports or for the
        # ports that went down while the app was disabled depending on the mode.
        first_few = fpports[: len(fpports)/2]
        last_few  = fpports[len(fpports)/2 :]
        # Bring down the first set of ports and verify the app triggered.
        logger.info("Bringing down first set of ports %s", first_few)
        ports_down(self, first_few)
        logger.info("  Waiting for packets to be generated")
        wait_for_generation(self, shdl, dt, app_id, tmo=2)
        logger.info("  Verifying trigger")
        self.verify_trigger(shdl, trgt, app_id, batch_size, first_few)
        # Disable app.
        logger.info("Disabling port down app %d", app_id)
        self.conn_mgr.pktgen_app_disable(shdl, dt, app_id)
        self.conn_mgr.complete_operations(shdl)
        # Bring down the rest of the ports.
        logger.info("  Bringing down second set of ports %s", last_few)
        ports_down(self, last_few)
        # Re-enable the app and check that it triggered.
        logger.info("Enabling port down app %d", app_id)
        self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
        self.conn_mgr.complete_operations(shdl)
        wait_for_generation(self, shdl, dt, app_id, tmo=2)
        if mode == 'all':
          logger.info("  Verifying trigger for all %d ports", len(fpports))
          self.verify_trigger(shdl, trgt, app_id, batch_size, fpports)
        else:
          logger.info("  Verifying trigger for %d missed ports", len(last_few))
          self.verify_trigger(shdl, trgt, app_id, batch_size, last_few)
        # Bring the ports back up.
        logger.info("Bringing all ports back up")
        ports_up(self, fpports)
        # Clear port down state and clean up table entries.
        logger.info("Clearing pkt-gen port-down state for all ports")
        for port in fpports:
          self.conn_mgr.pktgen_clear_port_down(shdl, dev_id, port)
        cleanup_one_table(self, 'i.t_port_down_batch_check')
      logger.info("Success")
    finally:
      logger.info("Cleanup")
      ports_up(self, fpports)
      if shdl:
        self.conn_mgr.pktgen_port_down_replay_mode_set(shdl, dt, PktGenPortDownReplay_t.REPLAY_NONE)
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)

  def verify_trigger(self, shdl, trgt, app_id, batch_size, ports):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    num_triggers = len(ports)
    batch_per_trig = 1
    # Get the app counters
    trig_cnt = self.conn_mgr.pktgen_get_trigger_counter(shdl, dt, app_id)
    batch_cnt = self.conn_mgr.pktgen_get_batch_counter(shdl, dt, app_id)
    pkt_cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
    # Reset the app counters
    self.conn_mgr.pktgen_set_trigger_counter(shdl, dt, app_id, 0)
    self.conn_mgr.pktgen_set_batch_counter(shdl, dt, app_id, 0)
    self.conn_mgr.pktgen_set_pkt_counter(shdl, dt, app_id, 0)
    # Verify the counters against the expected values
    if trig_cnt != num_triggers or batch_cnt != batch_per_trig * num_triggers or pkt_cnt != batch_size * num_triggers:
      logger.error("App counts don't match.")
      logger.error("  Trigger: Got %d, expected %d", trig_cnt, num_triggers)
      logger.error("  Batch  : Got %d, expected %d*%d", batch_cnt, batch_per_trig, num_triggers)
      logger.error("  Packet : Got %d, expected %d*%d*%d", pkt_cnt, batch_per_trig, batch_size, num_triggers)
      self.assertEqual(trig_cnt, num_triggers)
      self.assertEqual(batch_cnt, batch_per_trig * num_triggers)
      self.assertEqual(pkt_cnt, batch_per_trig * batch_size * num_triggers)
    if 0 == trig_cnt: return
    # Check the MAU stats tables
    good_pkt,good_byte = get_cntr(self, trgt, 'i.seq_no_cntr', app_id*2)
    bad_pkt,bad_byte = get_cntr(self, trgt, 'i.seq_no_cntr', app_id*2 + 1)
    if pkt_cnt != good_pkt or 0 != bad_pkt:
      logger.error("SeqNum-Cntr check failed app %d: expected %d got good %d bad %d", app_id, pkt_cnt, good_pkt, bad_pkt)
      logger.error("Trigger : %d", trig_cnt)
      logger.error("Batch   : %d", batch_cnt)
      logger.error("Packet  : %d", pkt_cnt)
    self.assertEqual(pkt_cnt, good_pkt)
    self.assertEqual(0, bad_pkt)
    for port in ports:
      p,b = get_cntr(self, trgt, 'i.port_down_cntr', port)
      self.assertEqual(p, batch_size)
    # Clear the MAU stats tables after checking their values
    clr_cntr(self, trgt, 'i.seq_no_cntr', app_id*2)
    clr_cntr(self, trgt, 'i.seq_no_cntr', app_id*2 + 1)
    for port in ports:
      clr_cntr(self, trgt, 'i.port_down_cntr', port)




class TestDprsrTrig(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    pktlen = 64
    pgen_port = 7 # Use port 7 in each pipe for pktgen dprsr app
    trigger_pgen_port = 6 # Use port 7 in each pipe for pktgen timer app
    pgen_port_speed = bf_port_speeds.BF_PORT_SPEED_50G
    ingr_port = 10 # Fake ingress port for generated dprsr trigger packets
    trigger_pkt_ingr_port = 71 # Fake ingress port for generated timer packets
    dprsr_hdr_idx = 3
    if g_target_model:
      batch_count = 1 + random.choice(range(5))
      batch_size = 1 + random.choice(range(10))
    else:
      batch_count = 1 + random.choice(range(16*1024))
      batch_size = 1 + random.choice(range(16*1024))
    app_id = random.choice(all_app_ids)
    trigger_app_id = (app_id + 1) % 16
    logger.info("App %d: %d batches of %d packets", app_id, batch_count, batch_size)
    try:
      cleanup(self)
      shdl = self.conn_mgr.client_init()
      rmv_special_ports(self)

      # Set up the app-info table
      t = self.bfrt_info.table_get('i.app_info')
      t.entry_add(trgt,
                  [t.make_key([gc.KeyTuple('md.app_id', app_id)])],
                  [t.make_data([gc.DataTuple('type', 4),
                                gc.DataTuple('batch_count', batch_count-1),
                                gc.DataTuple('batch_size', batch_size-1)],
                               'i.init_app_info')])
      # Set up the parser.
      t = self.bfrt_info.table_get('iPrsr.recirc_dprsr_apps')
      t.entry_add(trgt, [t.make_key([gc.KeyTuple('app_id', app_id, 0xF)])], None)
      t = self.bfrt_info.table_get('iPrsr.timer_apps')
      t.entry_add(trgt, [t.make_key([gc.KeyTuple('app_id', trigger_app_id, 0xF)])], None)

      # Set up the phase0 data for the deparser triggered packets.
      add_p0_entry(self, trgt, ingr_port, is_pktgen=True, dst_port=swports[-1])

      # Set up the phase0 data for the trigger packet.
      add_p0_entry(self, trgt, trigger_pkt_ingr_port, is_pktgen=True, dst_port=swports[-1], do_dprsr_trigger=True, dprsr_trigger_hdr_idx=dprsr_hdr_idx, dprsr_trigger_offset=0, dprsr_trigger_len=pktlen)

      # Set up the ctx data to pass from the trigger packet to the generated packets.
      data_first_pass = '\xFE\xDC\xBA\x98\x76\x54\x43\x21\x01\x23\x45\x67\x89\xAB\xCD\xEF'
      if g_target_hw:
        data_second_pass = data_first_pass[::-1]
      else:
        data_second_pass = data_first_pass[::-1]
      t = self.bfrt_info.table_get('i.t_set_dprsr_trig_hdr')
      t.entry_add(trgt,
                  [t.make_key([gc.KeyTuple('md.port_md.dprsr_trigger_hdr_idx', dprsr_hdr_idx)])],
                  [t.make_data([gc.DataTuple('h', bytearray(data_first_pass))], 'i.set_dprsr_trig_hdr')])

      # Set up the checker table to validate the data on the generated packet.
      t = self.bfrt_info.table_get('i.t_app_ctx_check')
      t.entry_add(trgt,
                  [t.make_key([gc.KeyTuple('md.app_id', app_id),
                               gc.KeyTuple('hdr.app_ctx.data', bytearray(data_second_pass))])],
                  [t.make_data([], 'i.app_ctx_okay')])

      # Setup a port for pktgen to generate traffic with.
      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)
        port = make_port(pipe, trigger_pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)

      # Configure the deparser trigger app and enable it.
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.DPRSR,
                                batch_count=batch_count-1,
                                pkt_count=batch_size-1,
                                buffer_offset=0,
                                length=pktlen,
                                assigned_chnl_id=pgen_port,
                                src_port=ingr_port)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      p = simple_ip_packet(pktlen=pktlen)
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, pktlen, str(p))
      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)

      # Setup a one-shot timer to create a packet to trigger the deparser app.
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                                batch_count=0,
                                pkt_count=0,
                                buffer_offset=0,
                                length=pktlen,
                                assigned_chnl_id=trigger_pgen_port,
                                src_port=trigger_pkt_ingr_port)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, trigger_app_id, app)
      p = simple_ip_packet(pktlen=pktlen)
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, pktlen, str(p))
      self.conn_mgr.complete_operations(shdl)

      # Turn on the timer app to trigger the deparser app.
      self.conn_mgr.pktgen_app_enable(shdl, DevTarget_t(dev_id, 0), trigger_app_id)
      self.conn_mgr.complete_operations(shdl)
      wait_for_generation(self, shdl, dt, app_id)

      # Verify the trigger packet.  There should be one packet generated by the app
      trig_cnt = self.conn_mgr.pktgen_get_trigger_counter(shdl, dt, trigger_app_id)
      batch_cnt = self.conn_mgr.pktgen_get_batch_counter(shdl, dt, trigger_app_id)
      pkt_cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, trigger_app_id)
      self.assertEqual(trig_cnt, 1)
      self.assertEqual(batch_cnt, 1)
      self.assertEqual(pkt_cnt, 1)
      # The phase0 data should have matched in the verify table.
      pkt_cnt,byte_cnt = get_cntr(self, trgt, 'i.port_metadata_cntr', trigger_pkt_ingr_port)
      self.assertEqual(pkt_cnt, 1)
      # Counters for verifying the sequence number and batch number should be
      # correct as well; 1 good packet.
      good_pkt,good_byte = get_cntr(self, trgt, 'i.seq_no_cntr', trigger_app_id*2)
      bad_pkt,bad_byte = get_cntr(self, trgt, 'i.seq_no_cntr', trigger_app_id*2 + 1)
      self.assertEqual(good_pkt, 1)
      self.assertEqual(bad_pkt, 0)
      # And the packet contents should be correct
      verify_packet(self, p, swports[-1])

      # Verify the deparser-app packet.  There should be one event triggered.
      trig_cnt = self.conn_mgr.pktgen_get_trigger_counter(shdl, dt, app_id)
      batch_cnt = self.conn_mgr.pktgen_get_batch_counter(shdl, dt, app_id)
      pkt_cnt = self.conn_mgr.pktgen_get_pkt_counter(shdl, dt, app_id)
      expected_pkt_cnt = batch_size * batch_count
      self.assertEqual(trig_cnt, 1)
      self.assertEqual(batch_cnt, batch_count)
      self.assertEqual(pkt_cnt, expected_pkt_cnt)
      # The phase0 data should have matched in the veriy table.
      pkt_cnt,byte_cnt = get_cntr(self, trgt, 'i.port_metadata_cntr', ingr_port)
      self.assertEqual(pkt_cnt, expected_pkt_cnt)
      # Counters for verifying the sequence number and batch number should be
      # correct as well.
      good_pkt,good_byte = get_cntr(self, trgt, 'i.seq_no_cntr', app_id*2)
      bad_pkt,bad_byte = get_cntr(self, trgt, 'i.seq_no_cntr', app_id*2 + 1)
      self.assertEqual(good_pkt, expected_pkt_cnt)
      self.assertEqual(bad_pkt, 0)
      # Check the counts on the ctx verify counter.
      pkt_good,b = get_cntr(self, trgt, 'i.ctx_cntr', 2*app_id)
      pkt_bad,b  = get_cntr(self, trgt, 'i.ctx_cntr', 2*app_id + 1)
      if pkt_good != expected_pkt_cnt or pkt_bad != 0:
        logger.error("Ctx Counter mismatch, expected %d, got %d good and %d bad", expected_pkt_cnt, pkt_good, pkt_bad)
      self.assertEqual(pkt_good, expected_pkt_cnt)
      self.assertEqual(pkt_bad, 0)
      # And the packet contents should be correct
      for _ in range(expected_pkt_cnt-1):
        verify_packet(self, p, swports[-1])
      verify_packets(self, p, [swports[-1]])


    finally:
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)



class TestGap(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def get_batch_counts(self, limit):
    if g_target_model:
      batch_count = 1 + random.choice(range(5))
      batch_size = 1 + random.choice(range(10))
    else:
      while True:
        batch_count = 1 + random.choice(range(16*1024))
        batch_size = 1 + random.choice(range(16*1024))
        if batch_count * batch_size <= limit: break
    return batch_count,batch_size

  def runTest(self):
    shdl = None
    fifo_sz = 47104 + 47104

    try:
      shdl = self.conn_mgr.client_init()

      # Test zero jitter on different port speeds and packet sizes.
      for s in [64, 128, 256, 512, 1024, 2048, 4096, 9192]:
        for x in range(8):
          bc,bs = self.get_batch_counts(fifo_sz)
          self.one_case(shdl, pktlen=s, batch_count=bc, batch_size=bs, ibg=10000, ipg=10000, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_50G, ing_port=x)
        for x in [0,2,4,6]:
          bc,bs = self.get_batch_counts(fifo_sz)
          self.one_case(shdl, pktlen=s, batch_count=bc, batch_size=bs, ibg=10000, ipg=10000, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_100G, ing_port=x)

      # Test a small IPG/IBG (10ns)
      bc,bs = self.get_batch_counts(fifo_sz)
      self.one_case(shdl, pktlen=128, batch_count=bc, batch_size=bs, ibg=10, ipg=10, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_50G, ing_port=1)
      self.one_case(shdl, pktlen=128, batch_count=bc, batch_size=bs, ibg=10, ipg=10, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_100G, ing_port=6)

      # Test a zero IPG/IBG
      bc,bs = self.get_batch_counts(fifo_sz)
      self.one_case(shdl, pktlen=60, batch_count=bc, batch_size=bs, ibg=0, ipg=0, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_50G, ing_port=1)
      self.one_case(shdl, pktlen=60, batch_count=bc, batch_size=bs, ibg=0, ipg=0, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_100G, ing_port=6)

      # Test a large IPG/IBG (100ms, 1 sec)
      bc,bs = 3,10 # Use smaller counts so the test doesn't take too long
      self.one_case(shdl, pktlen=60, batch_count=bc, batch_size=bs, ibg=1000000000, ipg=100000000, ibg_jitter=0, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_50G, ing_port=1)
      self.one_case(shdl, pktlen=60, batch_count=bc, batch_size=bs, ibg=1000000000, ipg=100000000, ipg_jitter=0, speed=bf_port_speeds.BF_PORT_SPEED_100G, ing_port=6)

      us = 1000
      ms = 1000000

      # Test jitter between 100us and 100ms
      bc,bs = 100,100
      self.one_case(shdl, app_id=0, pktlen=64, batch_count=bc, batch_size=bs, ibg_jitter=150*us, ipg_jitter=100*us, ing_port=0)
      self.one_case(shdl, app_id=2, pktlen=64, batch_count=bc, batch_size=bs, ibg_jitter=100*ms, ipg_jitter=100*us, ing_port=2)
      self.one_case(shdl, app_id=6, pktlen=64, batch_count=bc, batch_size=bs, ibg_jitter=6*ms, ipg_jitter=1*ms, ing_port=6)
      bc,bs = 1,500
      self.one_case(shdl, app_id=7, pktlen=64, batch_count=bc, batch_size=bs, ibg_jitter=0, ipg_jitter=5*ms, ing_port=7)
      self.one_case(shdl, app_id=4, pktlen=64, batch_count=bc, batch_size=bs, ibg_jitter=0, ipg_jitter=100*ms, ing_port=4)

    finally:
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)

  def get_pkt_size_delay(self, size, speed):
    """
           50G     100G
    Bytes  ns      ns
    64     22      13
    128    29      16
    256    48      26
    512    80      42
    1024   150     77
    2048   285    144
    4096   560    281
    9192   1238   621
    samples_50g  = [(60,20), (64,22), (128,29), (256,48), (512,80), (1024,150), (2048,285), (4096,560), (9192,1238)]
    samples_100g = [(60,12), (64,13), (128,16), (256,26), (512,42), (1024,77),  (2048,144), (4096,281), (9192,621)]
    if speed == bf_port_speeds.BF_PORT_SPEED_100G:
      samples = samples_100g
    else:
      samples = samples_50g

    if size <= samples[0][0]:
      delay = samples[0][1]
    elif size >= samples[-1][0]:
      delay =samples[-1][1] 
    else:
      for i in range(len(samples)-1):
        if size >= samples[i][0] and size < samples[i+1][0]:
          try:
            delay = samples[i][1] + (size-samples[i][0])/float(samples[i+1][0]-samples[i][0]) * (samples[i+1][1]-samples[i][1])
          except IndexError: pdb.set_trace()
    return int(delay + 0.5)
    """
    total_size = size + 6 + 4 + 32
    slots = (total_size + 47) / 48
    cycles_per_sec = 1/1.25 # Assumes 1.25GHz clock
    if speed == bf_port_speeds.BF_PORT_SPEED_100G:
      return int(slots * 4 * cycles_per_sec)
    return int(slots * 8 * cycles_per_sec)

  def one_case(self, shdl, app_id=None, pktlen=64, batch_count=1, batch_size=2, ibg=0, ipg=0, ibg_jitter=0, ipg_jitter=0, speed=None, ing_port=None):
    neg_slack = 0
    pos_slack = 16
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    pgen_port = random.choice(range(8))
    if ing_port is not None:
      pgen_port = ing_port
    if pgen_port & 1:
      pgen_port_speed = bf_port_speeds.BF_PORT_SPEED_50G
    else:
      pgen_port_speed = random.choice([bf_port_speeds.BF_PORT_SPEED_50G, bf_port_speeds.BF_PORT_SPEED_100G])
    if speed is not None:
      pgen_port_speed = speed
    ingr_port = random.choice(range(8,72)) # Fake ingress port for generated packets
    if app_id is None:
      app_id = random.choice(all_app_ids)
    pkt_size_delay = self.get_pkt_size_delay(pktlen, pgen_port_speed)

    logger.info("PGen local port %d, speed %s", pgen_port, bf_port_speeds._VALUES_TO_NAMES[pgen_port_speed])
    logger.info("App %d: %d batches of %d %d byte packets", app_id, batch_count, batch_size, pktlen)
    logger.info("IBG %d IBG-Jitter %d", ibg, ibg_jitter)
    logger.info("IPG %d IPG-Jitter %d", ipg, ipg_jitter)
    logger.info("Packet size delay %d", pkt_size_delay)

    cleanup(self)
    rmv_special_ports(self)
    for p in recirc_ports:
      self.conn_mgr.recirculation_enable(shdl, dev_id, p)

    # Set up the app-info table
    t = self.bfrt_info.table_get('i.app_info')
    t.entry_add(trgt,
                [t.make_key([gc.KeyTuple('md.app_id', app_id)])],
                [t.make_data([gc.DataTuple('type', 4),
                              gc.DataTuple('batch_count', batch_count-1),
                              gc.DataTuple('batch_size', batch_size-1)],
                             'i.init_app_info')])

    # Set up the parser.
    t = self.bfrt_info.table_get('iPrsr.timer_apps')
    t.entry_add(trgt, [t.make_key([gc.KeyTuple('app_id', app_id, 0xF)])], None)

    # Set up the phase0 data for the generated packets.  Set valid to false to
    # drop all packets.
    for p in range(num_pipes):
      port = make_port(p, ingr_port)
      add_p0_entry(self, trgt, port, is_pktgen=True, is_valid=False)

    # Setup a port for pktgen to generate traffic with.
    for pipe in range(num_pipes):
      port = make_port(pipe, pgen_port)
      self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
      self.conn_mgr.pktgen_enable(shdl, dev_id, port)

    # Configure a timer app.
    app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                              batch_count=batch_count-1,
                              pkt_count=batch_size-1,
                              buffer_offset=0,
                              length=pktlen,
                              assigned_chnl_id=pgen_port,
                              src_port=ingr_port,
                              ibg=ibg,
                              ipg=ipg,
                              ibg_jitter=ibg_jitter,
                              ipg_jitter=ipg_jitter)
    self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
    p = simple_ip_packet(pktlen=pktlen)
    self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, pktlen, str(p))

    # Turn on the app, wait for it to finish.
    self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
    self.conn_mgr.complete_operations(shdl)
    # If the gaps are greater than a half second pass an extended timeout to
    # the wait-for-generation function.
    tmo = 0.5
    if ibg+ibg_jitter > 500000000 or ipg+ipg_jitter > 500000000:
      tmo = max(ibg+ibg_jitter, ipg+ipg_jitter) / 1000000000.0
      logger.info("Using extended timeout %f", tmo)
    wait_for_generation(self, shdl, dt, app_id, tmo=tmo)
    self.conn_mgr.pktgen_app_disable(shdl, dt, app_id)

    failed = False

    # Poll the FIFO occupancy until it has all the packets in it.
    for p in range(num_pipes):
      logger.info("Checking pipe %d", p)
      d = DevTarget_t(dev_id, p)
      for i in range(10):
        occ_1 = self.client.register_occupancy_i_ts_fifo_1(shdl, d)
        occ_2 = self.client.register_occupancy_i_ts_fifo_2(shdl, d)
        occ = occ_1 + occ_2
        logger.info("  FIFO occupancy is %d (%d + %d)", occ, occ_1, occ_2)
        if occ != batch_count * batch_size:
          time.sleep(0.5)
        else:
          break
      self.assertEqual(occ, batch_count * batch_size)
      vals_1 = self.client.register_dequeue_i_ts_fifo_1(shdl, d, occ_1)
      vals_2 = self.client.register_dequeue_i_ts_fifo_2(shdl, d, occ_2)
      vals = vals_1 + vals_2
      self.assertEqual(len(vals_1), occ_1)
      self.assertEqual(len(vals_2), occ_2)
      self.assertEqual(len(vals), occ)

      # Go through the log and get the timestamp deltas per app-id.
      deltas = {}
      tstamps = {}
      for a in all_app_ids: deltas[a] = list()
      for a in all_app_ids: tstamps[a] = list()
      last_ts = [0]*len(all_app_ids)
      for i in range( len(vals) ):
        x = vals[i]
        this_app = i32_to_hex(x.f0) >> 28
        self.assertIn(this_app, all_app_ids)
        this_ts = ((i32_to_hex(x.f0) & 0xFFFF) << 32) | i32_to_hex(x.f1)
        this_delta = this_ts - last_ts[this_app]
        #logger.info("App %2d TS 0x%09x Delta %16d - %16d = %12d", this_app, this_ts, this_ts, last_ts[this_app], this_delta)
        last_ts[this_app] = this_ts
        if i > 0: deltas[this_app].append(this_delta)
        tstamps[this_app].append((this_ts, this_delta))

      failing_pkts = []
      variance_p = 0
      variance_b = 0
      for i,delta in enumerate(deltas[app_id]):
        if batch_size == 1:
          is_batch_gap = True
        else:
          is_batch_gap = ((i+1) % batch_size) == 0
        if is_batch_gap:
          min_gap = ibg + pkt_size_delay - neg_slack
          max_gap = ibg + ibg_jitter + pkt_size_delay + pos_slack
          if delta < min_gap or delta > max_gap:
            if not g_target_model:
              logger.info("Packets %d and %d had BATCH gap of %d, IBG=%d IBG-Jitter=%d, excess=%d", i, i+1, delta, ibg, ibg_jitter, delta-ibg)
            failed = True
            failing_pkts.append( (i, is_batch_gap) )
          variance_b += delta - min_gap
        else:
          min_gap = ipg + pkt_size_delay - neg_slack
          max_gap = ipg + ipg_jitter + pkt_size_delay + pos_slack
          if delta < min_gap or delta > max_gap:
            if not g_target_model:
              logger.info("Packets %d and %d had PKT gap of %d, IPG=%d IPG-Jitter=%d, excess=%d", i, i+1, delta, ipg, ipg_jitter, delta-ipg)
            failed = True
            failing_pkts.append( (i, is_batch_gap) )
          variance_p += delta - min_gap

      variance_b = variance_b / batch_count
      if batch_size > 1:
        variance_p = variance_p / (batch_count * (batch_size-1) )
      else:
        variance_p = 0
      if ibg_jitter:
        p = 100.0*variance_b/ibg_jitter
        logger.info("Batch Jitter Avg:  %d  %f", variance_b, p)
        if p < 35.0 or p > 65.0:
          logger.error("Batch Average Jitter Out of Range: %f", p)
          failed = True

      if ipg_jitter:
        p = 100.0*variance_p/ipg_jitter
        logger.info("Packet Jitter Avg: %d  %f", variance_p, p)
        if p < 35.0 or p > 65.0:
          logger.error("Packet Average Jitter Out of Range: %f", p)
          failed = True

      """
      # Dump a bit more detail about any failures.
      pkt_ctx = 10
      if not g_target_model:
        pdb.set_trace()
        for i,is_batch_gap in failing_pkts:
          err_pkt_1 = i
          err_pkt_2 = i+1
          s = max(err_pkt_1 - pkt_ctx, 0)
          e = min(len(tstamps[app_id])-1, err_pkt_2 + pkt_ctx)
          logger.info("Context for delta %d, pkts %d %d, range is %d (max of %d 0) to %d (min of %d %d)", i, err_pkt_1, err_pkt_2, s, e, err_pkt_1 - pkt_ctx, len(tstamps[app_id])-1, err_pkt_2 + pkt_ctx)
          for x in range(s, e+1):
            x_ts,x_delta = tstamps[app_id][x]
            logger.info("Packet %4d TS %16d   Delta %16d", x, x_ts, x_delta)
      """

    # The model doesn't track time accurately so ignore failures due to timing.
    if g_target_model: failed = False
    self.assertFalse(failed)



class TestConfig(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    failed = False
    try:
      cleanup(self)
      shdl = self.conn_mgr.client_init()
      rmv_special_ports(self)

      # Set up all recirc ports in each pipe as 50g or 100g
      ports = []
      for pipe in range(num_pipes):
        port = 0;
        while port < 8:
          dev_port = make_port(pipe, port)
          if (port & 1) == 0:
            speed = random.choice([bf_port_speeds.BF_PORT_SPEED_50G, bf_port_speeds.BF_PORT_SPEED_100G])
          else:
            speed = bf_port_speeds.BF_PORT_SPEED_50G
          logger.info("Pipe.Port %d.%d adding as %s", pipe, port, bf_port_speeds._VALUES_TO_NAMES[speed])
          self.conn_mgr.recirculation_enable(shdl, dev_id, dev_port)
          self.devport_mgr.devport_mgr_add_port(dev_id, dev_port, speed, bf_fec_types.BF_FEC_TYP_NONE)
          ports.append(dev_port)
          port = port + 1
          if speed == bf_port_speeds.BF_PORT_SPEED_100G:
            port = port + 1

      # Add phase0 entries to loop each recirc port to itself.
      for port in ports:
        add_p0_entry(self, trgt, port, dst_port=port)

      # Start a packet looping on each port, let it loop for a bit and then
      # bring it back and verify it.
      for l in [9100, 64, 100, 500, 1500]:
        for port in ports:
          add_p0_entry(self, trgt, fpports[0], dst_port=port)
          p = simple_ip_packet(pktlen=l)
          send_packet(self, fpports[0], str(p))
          logger.info("Letting packet loop on port %d size %d", port, l)
          time.sleep(3)
          c,_ = get_cntr(self, trgt, 'i.port_cntr', port)
          self.assertGreater(c, 0)
          add_p0_entry(self, trgt, port, dst_port=fpports[0])
          verify_packet(self, p, fpports[0])
      verify_no_other_packets(self, timeout=2)

      cleanup_cntr_table(self, 'i.port_cntr', trgt)

      # Let packets loop on all ports at the same time.  Bring the packets out
      # one port at a time and verify the packets.
      if g_target_hw:
        # Start a packet looping on each port.
        exp_pkts = []
        for port in ports:
          add_p0_entry(self, trgt, fpports[0], dst_port=port)
          add_p0_entry(self, trgt, port, dst_port=port)
          p = simple_ip_packet(pktlen=random.choice([64, 100, 500, 1500, 910]))
          logger.info("Sending %d bytes to port %d", len(p), port)
          send_packet(self, fpports[0], str(p))
          time.sleep(1)
          exp_pkts.append(p)
        # Let packets loop, check the per-port counter and make sure traffic is
        # running
        logger.info("Letting packets loop...")
        cnts = {}
        for port in ports:
          p,_ = get_cntr(self, trgt, 'i.port_cntr', port)
          cnts[port] = p
        time.sleep(5)
        failed = False
        for port in ports:
          p,_ = get_cntr(self, trgt, 'i.port_cntr', port)
          if p <= cnts[port]:
            failed = True
            logger.error("Port %d expected cntr to be more than %d but it is %d", port, cnts[port], p)
        self.assertFalse(failed)
        # Bring the packets back and verify them.
        for pkt,port in zip(exp_pkts, ports):
          logger.info("Verifying packet on port", port)
          add_p0_entry(self, trgt, port, dst_port=fpports[0])
          verify_packet(self, pkt, fpports[0])
        verify_no_other_packets(self, timeout=3)

      cleanup_cntr_table(self, 'i.port_cntr', trgt)

      # Let packets loop on each port again but delete the port while traffic
      # runs.
      for pkt_sz in [64, 350, 1249, 9100, 64]:
        traffic_ports = []
        cnts = {}
        for port in ports:
          add_p0_entry(self, trgt, port, dst_port=port)
          add_p0_entry(self, trgt, fpports[0], dst_port=port)
          p = simple_ip_packet(pktlen=pkt_sz)
          logger.info("Sending 10 packets of size %d to port %d", pkt_sz, port)
          for _ in xrange(10):
            send_packet(self, fpports[0], str(p))
          traffic_ports.append(port)
          time.sleep(0.5)

        # They should all have traffic now so verify it.
        for port in ports:
          cnts[port],_ = get_cntr(self, trgt, 'i.port_cntr', port)
          if cnts[port] == 0:
            logger.error("Port %d expected cntr to be non-zero", port)
            failed = True
        self.assertFalse(failed)

        # Delete them one by one.
        to_del = list(ports)
        random.shuffle(to_del)
        while len(to_del):
          #port = to_del.pop()
          port = 262           # DEBUG
          to_del.remove(port)  # DEBUG
          logger.info("Removing port %d while traffic is running", port)
          pdb.set_trace()
          self.devport_mgr.devport_mgr_remove_port(dev_id, port)
          # All remaining ports should continue to carry traffic
          for p in to_del:
            cnts[p],_ = get_cntr(self, trgt, 'i.port_cntr', p)
          time.sleep(3)
          if len(to_del): logger.info("Checking traffic is still flowing on remaining ports: %s", to_del)
          for p in to_del:
            c,_ = get_cntr(self, trgt, 'i.port_cntr', p)
            if c <= cnts[p]:
              logger.error("Port %d expected cntr to be more than %d but it is %d", p, cnts[p], c)
              failed = True
            cnts[p] = c
          self.assertFalse(failed)

        # Add them back for the next packet size.
        ports = []
        for pipe in range(num_pipes):
          port = 0;
          while port < 8:
            dev_port = make_port(pipe, port)
            if (port & 1) == 0:
              speed = random.choice([bf_port_speeds.BF_PORT_SPEED_50G, bf_port_speeds.BF_PORT_SPEED_100G])
            else:
              speed = bf_port_speeds.BF_PORT_SPEED_50G
            logger.info("Pipe.Port %d.%d added as %s", pipe, port, bf_port_speeds._VALUES_TO_NAMES[speed])
            self.conn_mgr.recirculation_enable(shdl, dev_id, dev_port)
            self.devport_mgr.devport_mgr_add_port(dev_id, dev_port, speed, bf_fec_types.BF_FEC_TYP_NONE)
            ports.append(dev_port)
            port = port + 1
            if speed == bf_port_speeds.BF_PORT_SPEED_100G:
              port = port + 1
      logger.info("SUCCESS")
    finally:
      pdb.set_trace()
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)



class TestSnake(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    failed = False
    try:
      cleanup(self)
      shdl = self.conn_mgr.client_init()
      rmv_special_ports(self)

      # Pick two 100g ports to use for traffic generation.
      src_ports = [make_port(0,0), make_port(num_pipes-1, 6)]
      for p in src_ports:
        self.conn_mgr.recirculation_enable(shdl, dev_id, p)
        self.devport_mgr.devport_mgr_add_port(dev_id, p, bf_port_speeds.BF_PORT_SPEED_100G, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, p)

      # Set up remaining recirc ports in each pipe as 50g or 100g
      ports = []
      speeds = {}
      for pipe in range(num_pipes):
        port = 0;
        while port < 8:
          dev_port = make_port(pipe, port)
          if dev_port in src_ports:
            port = port + 2
            continue
          if (port & 1) == 0:
            speed = random.choice([bf_port_speeds.BF_PORT_SPEED_50G, bf_port_speeds.BF_PORT_SPEED_100G])
          else:
            speed = bf_port_speeds.BF_PORT_SPEED_50G
          speeds[port] = speed
          logger.info("Pipe.Port %d.%d added as %s", pipe, port, bf_port_speeds._VALUES_TO_NAMES[speed])
          self.conn_mgr.recirculation_enable(shdl, dev_id, dev_port)
          self.devport_mgr.devport_mgr_add_port(dev_id, dev_port, speed, bf_fec_types.BF_FEC_TYP_NONE)
          ports.append(dev_port)
          port = port + 1
          if speed == bf_port_speeds.BF_PORT_SPEED_100G:
            port = port + 1

      # Add phase0 entries to snake the traffic
      for i in range(len(ports)):
        next_port = ports[(i+1) % len(ports)]
        add_p0_entry(self, trgt, ports[i], dst_port=next_port)

      # Configure the packet generator to generate traffic for the snake.
      app1 = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_ONE_SHOT,
                                 length=58,
                                 buffer_offset=0,
                                 assigned_chnl_id=port_to_local_port(src_ports[0]),
                                 src_port=port_to_local_port(src_ports[0]))
      app2 = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.TIMER_PERIODIC,
                                 length=9000,
                                 buffer_offset=128,
                                 assigned_chnl_id=port_to_local_port(src_ports[1]),
                                 src_port=port_to_local_port(src_ports[1]))
      dt1 = DevTarget_t(dev_id, port_to_pipe(src_ports[0]))
      dt2 = DevTarget_t(dev_id, port_to_pipe(src_ports[1]))
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, 0, app1)
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, 1, app2)
      p = simple_ip_packet(pktlen=64)
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 0, len(str(p)), str(p))
      p = simple_ip_packet(pktlen=9000)
      self.conn_mgr.pktgen_write_pkt_buffer(shdl, dt, 128, len(str(p)), str(p))

      # Add phase0 entries to put the generated packets into the snake.
      add_p0_entry(self, trgt, src_ports[0], dst_port=ports[0])
      add_p0_entry(self, trgt, src_ports[1], dst_port=ports[len(ports)/2])

      # Start traffic.
      self.conn_mgr.complete_operations(shdl)
      self.conn_mgr.pktgen_app_enable(shdl, dt1, 0)
      self.conn_mgr.pktgen_app_enable(shdl, dt2, 1)
      self.conn_mgr.complete_operations(shdl)

      # Make sure traffic is going.
      time.sleep(3)
      cnts = {}
      for port in ports:
        cnts[port],_ = get_cntr(self, trgt, 'i.port_cntr', port)
      time.sleep(3)
      for port in ports:
        p,_ = get_cntr(self, trgt, 'i.port_cntr', port)
        if p <= cnts[port]:
          failed = True
          logger.error("Port %d expected cntr to be more than %d but it is %d", port, cnts[port], p)
      self.assertFalse(failed)

      # Delete a port and add it back.
      for port in ports:
        logger.info("Removing and adding port %d", port)
        self.devport_mgr.devport_mgr_remove_port(dev_id, port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, speeds[port], bf_fec_types.BF_FEC_TYP_NONE)

        # Make sure the snake is still working.
        for p in ports:
          cnts[p],_ = get_cntr(self, trgt, 'i.port_cntr', p)
        time.sleep(3)
        for p in ports:
          c,_ = get_cntr(self, trgt, 'i.port_cntr', p)
          if c <= cnts[p]:
            failed = True
            logger.error("Port %d expected cntr to be more than %d but it is %d", p, cnts[p], c)
        self.assertFalse(failed)

        # Do a few del-adds and check once more.
        logger.info("Removing and adding port %d a few times", port)
        for _ in xrange(100):
          self.devport_mgr.devport_mgr_remove_port(dev_id, port)
          self.devport_mgr.devport_mgr_add_port(dev_id, port, speeds[port], bf_fec_types.BF_FEC_TYP_NONE)

        # Make sure the snake is still working.
        for p in ports:
          cnts[p],_ = get_cntr(self, trgt, 'i.port_cntr', p)
        time.sleep(3)
        for p in ports:
          c,_ = get_cntr(self, trgt, 'i.port_cntr', p)
          if c <= cnts[p]:
            failed = True
            logger.error("Port %d expected cntr to be more than %d but it is %d", p, cnts[p], c)
        self.assertFalse(failed)

        # If this was a 100g port, add it back as a 50g port.
        if speeds[port] == bf_port_speeds.BF_PORT_SPEED_50G: continue
        logger.info("Removing and adding port %d and adding back as 50g", port)
        self.devport_mgr.devport_mgr_remove_port(dev_id, port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, bf_port_speeds.BF_PORT_SPEED_50G, bf_fec_types.BF_FEC_TYP_NONE)
        # Make sure the snake is still working.
        for p in ports:
          cnts[p],_ = get_cntr(self, trgt, 'i.port_cntr', p)
        time.sleep(3)
        for p in ports:
          c,_ = get_cntr(self, trgt, 'i.port_cntr', p)
          if c <= cnts[p]:
            failed = True
            logger.error("Port %d expected cntr to be more than %d but it is %d", p, cnts[p], c)
        self.assertFalse(failed)
        # Switch it back to a 100g port.
        logger.info("Removing and adding port %d and adding back as 50g", port)
        self.devport_mgr.devport_mgr_remove_port(dev_id, port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, speeds[port], bf_fec_types.BF_FEC_TYP_NONE)
        # Make sure the snake is still working.
        for p in ports:
          cnts[p],_ = get_cntr(self, trgt, 'i.port_cntr', p)
        time.sleep(3)
        for p in ports:
          c,_ = get_cntr(self, trgt, 'i.port_cntr', p)
          if c <= cnts[p]:
            failed = True
            logger.error("Port %d expected cntr to be more than %d but it is %d", p, cnts[p], c)
        self.assertFalse(failed)

      # Turn of the packet generators.
      self.conn_mgr.pktgen_app_disable(shdl, dt1, 0)
      self.conn_mgr.pktgen_app_disable(shdl, dt2, 1)

    finally:
      logger.info("Starting cleanup")
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      cleanup(self)



class TestPFC(BfRuntimeTest, pd_base_tests.ThriftInterfaceDataPlane):
  def __init__(self):
    BfRuntimeTest.__init__(self)
    pd_base_tests.ThriftInterfaceDataPlane.__init__(self, [p4_name])

  def setUp(self):
    pd_base_tests.ThriftInterfaceDataPlane.setUp(self)
    BfRuntimeTest.setUp(self, client_id, p4_name)
    setup_random()
    self.bfrt_info = self.interface.bfrt_info_get(p4_name)

  def runTest(self):
    # This test only runs on HW.
    if g_target_model: return
    # This test doesn't even run on HW without manual intervention
    return

    dt = DevTarget_t(dev_id, hex_to_i16(0xFFFF))
    trgt = gc.Target(device_id=dev_id)
    shdl = None
    pktlen = 64
    pgen_port = 7 # Use port 1 in each pipe for app
    pgen_port_speed = bf_port_speeds.BF_PORT_SPEED_50G
    ingr_port = pgen_port # Fake ingress port for generated packet
    batch_count = 1
    batch_size = 1
    app_id = random.choice(all_app_ids)
    logger.info("App %d: %d batches of %d packets", app_id, batch_count, batch_size)
    if g_target_model:
      egr_port = swports[-1]
    else:
      # Hardcode egress port to 8 for emulator testing
      egr_port = 8
    ing_port = 16
    egr_port = 20
    pgen_egr_port = 64

    try:
      cleanup(self)
      shdl = self.conn_mgr.client_init()
      rmv_special_ports(self)

      # Set up the app-info table
      t = self.bfrt_info.table_get('i.app_info')
      t.entry_add(trgt,
                  [t.make_key([gc.KeyTuple('md.app_id', app_id)])],
                  [t.make_data([gc.DataTuple('type', 5),
                                gc.DataTuple('batch_count', batch_count-1),
                                gc.DataTuple('batch_size', batch_size-1)],
                               'i.init_app_info')])
      logger.info("Added tbl entry")
      # Set up the parser.
      t = self.bfrt_info.table_get('iPrsr.pfc_apps')
      t.entry_add(trgt, [t.make_key([gc.KeyTuple('app_id', app_id, 0xF)])], None)
      logger.info("Added pvs entry")

      # Set up the phase0 data for the generated packet
      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        add_p0_entry(self, trgt, port, is_pktgen=True, dst_port=pgen_egr_port)
      logger.info("Added p0 entries")

      # Setup a port for pktgen to generate traffic with.
      for pipe in range(num_pipes):
        port = make_port(pipe, pgen_port)
        self.devport_mgr.devport_mgr_add_port(dev_id, port, pgen_port_speed, bf_fec_types.BF_FEC_TYP_NONE)
        self.conn_mgr.pktgen_enable(shdl, dev_id, port)
      logger.info("Added ports entry")

      # Configure the PFC app and enable it.
      pfc_hdr = [hex_to_byte((i<<4)|i) for i in range(16)]
      app = PktGenAppCfg_tof2_t(trigger_type=PktGenTriggerType_t.PFC,
                                length=100, # Fix me, length > 56 is required by driver.  Remove that restriction.
                                batch_count=batch_count-1,
                                pkt_count=batch_size-1,
                                assigned_chnl_id=pgen_port,
                                src_port=pgen_port,
                                pfc_max_msgs=16,
                                pfc_timer_en=False,
                                pfc_timer=1234,
                                pfc_hdr=pfc_hdr
                                )
      self.conn_mgr.pktgen_cfg_app_tof2(shdl, dt, app_id, app)
      logger.info("Configured PFC app")
      self.conn_mgr.pktgen_app_enable(shdl, dt, app_id)
      logger.info("Enabled PFC app")

      # Create a forwarding entry to send ingress traffic out the same port.
      add_p0_entry(self, trgt, ing_port, dst_port=egr_port)

      # Create a PPG on the ingress port
      ppg = self.tm.tm_allocate_ppg(dev_id, ing_port)
      self.tm.tm_set_ppg_guaranteed_min_limit(dev_id, ppg, 200)
      self.tm.tm_set_ppg_skid_limit(dev_id, ppg, 120)
      self.tm.tm_set_ppg_icos_mapping(dev_id, ppg, 0xFF)
      self.tm.tm_enable_lossless_treatment(dev_id, ppg)
      # Enable PFC (not pause)
      self.tm.tm_set_port_flowcontrol_mode(dev_id, ing_port, 1)
      icos_map = tm_pfc_cos_map_t(CoS0_to_iCos=0,
                                  CoS1_to_iCos=1,
                                  CoS2_to_iCos=2,
                                  CoS3_to_iCos=3,
                                  CoS4_to_iCos=4,
                                  CoS5_to_iCos=5,
                                  CoS6_to_iCos=6,
                                  CoS7_to_iCos=7)
      self.tm.tm_set_port_pfc_cos_mapping(dev_id, ing_port, icos_map)
      # Queue Config
      self.tm.tm_set_q_guaranteed_min_limit(dev_id, egr_port, 0, 500)
      #self.tm.tm_set_q_guaranteed_min_limit(dev_id, egr_port, 0, 384000)
      self.tm.tm_set_q_shaping_rate(dev_id, egr_port, 0, True, 5000, 3500)
      self.tm.tm_enable_q_max_shaping_rate(dev_id, egr_port, 0)

      raw_input("Hit enter to clean up")

    finally:
      if shdl:
        self.conn_mgr.client_cleanup(shdl)
      #cleanup(self)
